{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load kedro environment (not needed in .py)\n",
    "from pathlib import Path\n",
    "from kedro.framework.context import load_context\n",
    "\n",
    "# Load a context to be able to work in the notebook\n",
    "#current_dir = Path.cwd()\n",
    "current_dir = Path(\"/u01/share/cesar/aa_engine_uy/notebooks/\")\n",
    "proj_path = current_dir.parent\n",
    "context = load_context(proj_path)\n",
    "catalog = context.catalog\n",
    "credentials = context.config_loader.get(\"credentials*\",\"credentials*/**\")\n",
    "parameters = context.config_loader.get(\"parameters*\",\"parameters*/**\")\n",
    "\n",
    "from aa_engine_pkg.assets.utils import *\n",
    "from aa_engine_pkg.assets.core.data.kedro.catalog_expansion.partitioned_sql import SQLPartitionedDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cliente_activo(cliente_activo: SQLPartitionedDataSet,\n",
    "                          date: str) -> pd.DataFrame:\n",
    "    \"\"\"Creates master table with features related to EoP state of customers for one period of data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cliente_activo:\n",
    "        dataset defined in ´catalog.yml´ - list of active customers at EoP for the given period\n",
    "    date:\n",
    "        period to process\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        Mastertable with information of clientes at EoP\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize logger\n",
    "    log = initialize_logger()\n",
    "\n",
    "    # Load active clientes for period\n",
    "    log.info(f\"Creating cliente_activo...\")\n",
    "    period_to_load = get_previous_month(date)\n",
    "    df_clientes_activos = cliente_activo.filter_by(date=period_to_load)\n",
    "\n",
    "    # Return\n",
    "    return df_clientes_activos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-04 17:41:08,506 - kedro.io.data_catalog - INFO - Loading data from `cliente_activo` (SQLPartitionedDataSet)...\n"
     ]
    }
   ],
   "source": [
    "cliente_activo=catalog.load(\"cliente_activo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [\"CUSTOMER_ID\", \"DATE_EXP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_total(cliente_activo: pd.DataFrame,\n",
    "                        master_arpu_quality: pd.DataFrame,\n",
    "                        master_campanas: pd.DataFrame,\n",
    "                        master_clientes: pd.DataFrame,\n",
    "                        master_eop: pd.DataFrame,\n",
    "                        master_plan_evento: pd.DataFrame,\n",
    "                        master_servicioalcliente: pd.DataFrame,\n",
    "                        master_mudanza: pd.DataFrame,\n",
    "                        master_echi: pd.DataFrame,\n",
    "                        master_mantenimiento: pd.DataFrame,\n",
    "                        master_mora: pd.DataFrame,\n",
    "                        master_eventos_fact: pd.DataFrame,\n",
    "                        parameters: Dict,\n",
    "                        date: str) -> Union[pd.DataFrame, None]:\n",
    "    \"\"\"Function that takes care of master table unification (i.e., merging the different master tables of the data\n",
    "    sources into one table) for one period defined in the ``date`` parameter.\n",
    "    The function receives pandas dataframes created in previous nodes, performs a merge and saves\n",
    "    the master as parquet file.\n",
    "    # TODO: incluir parámetros\n",
    "    Parameters\n",
    "    ----------\n",
    "    master_arpu_quality:\n",
    "        pandas dataframe with information regarding ARPU quality for active customers in period\n",
    "    master_campanas:\n",
    "        pandas dataframe with information regarding campañas for active customers in period\n",
    "    master_clientes:\n",
    "        pandas dataframe with active customers in period\n",
    "    master_eop:\n",
    "        pandas dataframe with information related to EoP state of active customers in period\n",
    "    master_plan_evento:\n",
    "        pandas dataframe with customer's events features for active customers in period\n",
    "    master_servicioalcliente:\n",
    "        pandas dataframe with call center calls features for active customers in period\n",
    "    date:\n",
    "        period to be generated, must be a string in \"yyyymmdd\" format\n",
    "    parameters:\n",
    "        set of project parameters defined in ``parameters.yml``\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Dataframe with unified master table information\n",
    "    Args:\n",
    "        master_mudanza:\n",
    "        master_echi:\n",
    "        master_mantenimiento:\n",
    "        master_mora:\n",
    "        master_eventos_fact:\n",
    "        cliente_activo:\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize logger\n",
    "    log = initialize_logger()\n",
    "\n",
    "    table_name = \"total\"\n",
    "    write_to_parquet = parameters[\"write_to_parquet\"]\n",
    "    write_subsample = parameters[\"masters\"][table_name][\"create_subsample\"]\n",
    "\n",
    "    path = f\"{parameters['paths']['master_path']}master_{table_name}/\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    processed_dates = os.listdir(path)\n",
    "    match = [file for file in processed_dates if str(date) in file]\n",
    "\n",
    "    if len(match) > 0:\n",
    "        # If table is found, read parquet:\n",
    "        log.info(f\"Reading {match[0]} table\")\n",
    "        df_final = pd.read_parquet(path + match[0], engine=\"pyarrow\")\n",
    "\n",
    "    else:\n",
    "        log.info(f\"Creating master table total for period {date}\")\n",
    "\n",
    "        # Reformat tables\n",
    "        # TODO\n",
    "        \"\"\"\n",
    "        masters_to_exclude = [\"total\", \"global\"]\n",
    "        \n",
    "        for master in set(parameters[\"masters\"].keys()).difference(masters_to_exclude):\n",
    "            if parameters[\"masters\"][master][\"include_in_total\"]:\n",
    "                tables_to_include.append(f\"master_{master}\")\n",
    "        \"\"\"\n",
    "        tables_to_include = [master_arpu_quality,\n",
    "                             master_campanas,\n",
    "                             master_clientes,\n",
    "                             master_eop,\n",
    "                             master_plan_evento,\n",
    "                             master_servicioalcliente,\n",
    "                             master_mudanza,\n",
    "                             master_echi,\n",
    "                             master_mantenimiento,\n",
    "                             master_mora,\n",
    "                             master_eventos_fact]\n",
    "        df_list = []\n",
    "        for df in tables_to_include:\n",
    "            to_drop = [c for c in df.columns if \"DATE\" in c]\n",
    "            df.drop(to_drop, axis=1, inplace=True)\n",
    "            df_list.append(df)\n",
    "\n",
    "        df_list = [df.set_index(\"CUSTOMER_ID\") for df in df_list]\n",
    "        log.info(f\"Merging all {len(df_list)} tables\")\n",
    "\n",
    "        # Merge into one df\n",
    "        df_final = pd.concat(df_list, axis=1)\n",
    "        df_final = df_final.reset_index()\n",
    "        del df_list;\n",
    "        gc.collect()\n",
    "\n",
    "        # Merge all with active customers\n",
    "        log.info(f\"Merging all tables with EOP\")\n",
    "        df_final = pd.merge(cliente_activo, df_final, on=\"CUSTOMER_ID\", how=\"left\", validate=\"1:1\")\n",
    "        df_final[\"DATE_CALC\"] = date\n",
    "\n",
    "        # Optimize memory usage of table before saving\n",
    "        log.info(\"Optimizing memory...\")\n",
    "        start_mem = df_final.memory_usage().sum() / 1024 ** 2\n",
    "        log.info('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "        df_final = Parallel(n_jobs=12, verbose=5, prefer=\"processes\")(\n",
    "            delayed(reduce_mem_usage)(df) for df in np.array_split(df_final, 1000)\n",
    "        )\n",
    "\n",
    "        df_final = pd.concat(df_final)\n",
    "        end_mem = df_final.memory_usage().sum() / 1024 ** 2\n",
    "        log.info('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "        log.info('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "        log.info(f\"Exporting {df_final.shape[0]} rows and {df_final.shape[1]} columns\")\n",
    "\n",
    "        # Save sample and total mastertable in parquet files\n",
    "        if write_to_parquet:\n",
    "            if write_subsample:\n",
    "                df_subsample = create_subsample(df=df_final,\n",
    "                                                subsample_col=\"CUSTOMER_ID\",\n",
    "                                                pct=0.2)\n",
    "                path_subsample = f\"{parameters['paths']['master_path']}master_subsample/\"\n",
    "                os.makedirs(path_subsample, exist_ok=True)\n",
    "                df_subsample.to_parquet(f\"{path_subsample}master_subsample_{date}.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "            file = f\"{path}master_{table_name}_{date}.parquet\"\n",
    "            df_final.to_parquet(file, engine=\"pyarrow\")\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20181203', '20181231', '20190128', '20190225', '20190325', '20190422']\n"
     ]
    }
   ],
   "source": [
    "dates = calculate_dates_to_process_for_master(parameters, table_name=\"total\")\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/uy_po/master/master_'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=parameters['paths']['master_path']+f'master_'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing date 20181203\n",
      "2021-01-04 17:59:39,313 - aa_engine_pkg.assets.utils.utilities - INFO - Creating cliente_activo...\n",
      "select distinct CUSTOMER_ID from stg_uy_customer_status where UPPER(STATUS) LIKE '%ACTIVO%' and DATE_EXP = 201811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u01/miniconda3/envs/uypo37/lib/python3.7/site-packages/sqlalchemy/dialects/oracle/base.py:1381: SAWarning: Oracle version (19, 5, 0, 0, 0) is known to have a maximum identifier length of 128, rather than the historical default of 30. SQLAlchemy 1.4 will use 128 for this database; please set max_identifier_length=128 in create_engine() in order to test the application with this new length, or set to 30 in order to assure that 30 continues to be used.  In particular, pay close attention to the behavior of database migrations as dynamically generated names may change. See the section 'Max Identifier Lengths' in the SQLAlchemy Oracle dialect documentation for background.\n",
      "  % ((self.server_version_info,))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-04 17:59:44,389 - aa_engine_pkg.assets.utils.utilities - INFO - Creating master table total for period 20181203\n",
      "2021-01-04 17:59:45,011 - aa_engine_pkg.assets.utils.utilities - INFO - Merging all 11 tables\n",
      "2021-01-04 17:59:47,070 - aa_engine_pkg.assets.utils.utilities - INFO - Merging all tables with EOP\n",
      "2021-01-04 17:59:48,455 - aa_engine_pkg.assets.utils.utilities - INFO - Optimizing memory...\n",
      "2021-01-04 17:59:48,513 - aa_engine_pkg.assets.utils.utilities - INFO - Memory usage of dataframe is 823.11 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=12)]: Done 624 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=12)]: Done 858 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-04 18:01:55,183 - aa_engine_pkg.assets.utils.utilities - INFO - Memory usage after optimization is: 413.78 MB\n",
      "2021-01-04 18:01:55,184 - aa_engine_pkg.assets.utils.utilities - INFO - Decreased by 49.7%\n",
      "2021-01-04 18:01:55,185 - aa_engine_pkg.assets.utils.utilities - INFO - Exporting 116634 rows and 924 columns\n",
      "Processing date 20181231\n",
      "2021-01-04 18:02:00,673 - aa_engine_pkg.assets.utils.utilities - INFO - Creating cliente_activo...\n",
      "select distinct CUSTOMER_ID from stg_uy_customer_status where UPPER(STATUS) LIKE '%ACTIVO%' and DATE_EXP = 201811\n",
      "2021-01-04 18:02:05,787 - aa_engine_pkg.assets.utils.utilities - INFO - Creating master table total for period 20181231\n",
      "2021-01-04 18:02:06,328 - aa_engine_pkg.assets.utils.utilities - INFO - Merging all 11 tables\n",
      "2021-01-04 18:02:08,315 - aa_engine_pkg.assets.utils.utilities - INFO - Merging all tables with EOP\n",
      "2021-01-04 18:02:09,685 - aa_engine_pkg.assets.utils.utilities - INFO - Optimizing memory...\n",
      "2021-01-04 18:02:09,743 - aa_engine_pkg.assets.utils.utilities - INFO - Memory usage of dataframe is 829.34 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=12)]: Done 624 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=12)]: Done 858 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-04 18:04:14,898 - aa_engine_pkg.assets.utils.utilities - INFO - Memory usage after optimization is: 417.78 MB\n",
      "2021-01-04 18:04:14,899 - aa_engine_pkg.assets.utils.utilities - INFO - Decreased by 49.6%\n",
      "2021-01-04 18:04:14,900 - aa_engine_pkg.assets.utils.utilities - INFO - Exporting 116634 rows and 931 columns\n",
      "Processing date 20190128\n",
      "2021-01-04 18:04:20,428 - aa_engine_pkg.assets.utils.utilities - INFO - Creating cliente_activo...\n",
      "select distinct CUSTOMER_ID from stg_uy_customer_status where UPPER(STATUS) LIKE '%ACTIVO%' and DATE_EXP = 201812\n",
      "2021-01-04 18:04:25,260 - aa_engine_pkg.assets.utils.utilities - INFO - Creating master table total for period 20190128\n",
      "2021-01-04 18:04:25,769 - aa_engine_pkg.assets.utils.utilities - INFO - Merging all 11 tables\n",
      "2021-01-04 18:04:27,782 - aa_engine_pkg.assets.utils.utilities - INFO - Merging all tables with EOP\n",
      "2021-01-04 18:04:29,167 - aa_engine_pkg.assets.utils.utilities - INFO - Optimizing memory...\n",
      "2021-01-04 18:04:29,227 - aa_engine_pkg.assets.utils.utilities - INFO - Memory usage of dataframe is 838.07 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=12)]: Done 624 tasks      | elapsed:   57.5s\n",
      "[Parallel(n_jobs=12)]: Done 858 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-04 18:06:35,561 - aa_engine_pkg.assets.utils.utilities - INFO - Memory usage after optimization is: 421.71 MB\n",
      "2021-01-04 18:06:35,562 - aa_engine_pkg.assets.utils.utilities - INFO - Decreased by 49.7%\n",
      "2021-01-04 18:06:35,563 - aa_engine_pkg.assets.utils.utilities - INFO - Exporting 116984 rows and 938 columns\n",
      "Processing date 20190225\n",
      "2021-01-04 18:06:41,180 - aa_engine_pkg.assets.utils.utilities - INFO - Creating cliente_activo...\n",
      "select distinct CUSTOMER_ID from stg_uy_customer_status where UPPER(STATUS) LIKE '%ACTIVO%' and DATE_EXP = 201901\n",
      "2021-01-04 18:06:44,271 - aa_engine_pkg.assets.utils.utilities - INFO - Creating master table total for period 20190225\n",
      "2021-01-04 18:06:44,795 - aa_engine_pkg.assets.utils.utilities - INFO - Merging all 11 tables\n",
      "2021-01-04 18:06:46,818 - aa_engine_pkg.assets.utils.utilities - INFO - Merging all tables with EOP\n",
      "2021-01-04 18:06:48,237 - aa_engine_pkg.assets.utils.utilities - INFO - Optimizing memory...\n",
      "2021-01-04 18:06:48,296 - aa_engine_pkg.assets.utils.utilities - INFO - Memory usage of dataframe is 837.02 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=12)]: Done 624 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=12)]: Done 858 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-04 18:08:53,459 - aa_engine_pkg.assets.utils.utilities - INFO - Memory usage after optimization is: 419.84 MB\n",
      "2021-01-04 18:08:53,460 - aa_engine_pkg.assets.utils.utilities - INFO - Decreased by 49.8%\n",
      "2021-01-04 18:08:53,461 - aa_engine_pkg.assets.utils.utilities - INFO - Exporting 116342 rows and 942 columns\n",
      "Processing date 20190325\n",
      "2021-01-04 18:08:59,135 - aa_engine_pkg.assets.utils.utilities - INFO - Creating cliente_activo...\n",
      "select distinct CUSTOMER_ID from stg_uy_customer_status where UPPER(STATUS) LIKE '%ACTIVO%' and DATE_EXP = 201902\n",
      "2021-01-04 18:09:02,172 - aa_engine_pkg.assets.utils.utilities - INFO - Creating master table total for period 20190325\n",
      "2021-01-04 18:09:02,681 - aa_engine_pkg.assets.utils.utilities - INFO - Merging all 11 tables\n",
      "2021-01-04 18:09:04,697 - aa_engine_pkg.assets.utils.utilities - INFO - Merging all tables with EOP\n",
      "2021-01-04 18:09:06,128 - aa_engine_pkg.assets.utils.utilities - INFO - Optimizing memory...\n",
      "2021-01-04 18:09:06,187 - aa_engine_pkg.assets.utils.utilities - INFO - Memory usage of dataframe is 833.18 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=12)]: Done 624 tasks      | elapsed:   57.0s\n",
      "[Parallel(n_jobs=12)]: Done 858 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-04 18:11:11,406 - aa_engine_pkg.assets.utils.utilities - INFO - Memory usage after optimization is: 417.91 MB\n",
      "2021-01-04 18:11:11,407 - aa_engine_pkg.assets.utils.utilities - INFO - Decreased by 49.8%\n",
      "2021-01-04 18:11:11,408 - aa_engine_pkg.assets.utils.utilities - INFO - Exporting 115807 rows and 942 columns\n",
      "Processing date 20190422\n",
      "2021-01-04 18:11:17,092 - aa_engine_pkg.assets.utils.utilities - INFO - Creating cliente_activo...\n",
      "select distinct CUSTOMER_ID from stg_uy_customer_status where UPPER(STATUS) LIKE '%ACTIVO%' and DATE_EXP = 201903\n",
      "2021-01-04 18:11:19,535 - aa_engine_pkg.assets.utils.utilities - INFO - Creating master table total for period 20190422\n",
      "2021-01-04 18:11:20,078 - aa_engine_pkg.assets.utils.utilities - INFO - Merging all 11 tables\n",
      "2021-01-04 18:11:22,088 - aa_engine_pkg.assets.utils.utilities - INFO - Merging all tables with EOP\n",
      "2021-01-04 18:11:23,513 - aa_engine_pkg.assets.utils.utilities - INFO - Optimizing memory...\n",
      "2021-01-04 18:11:23,572 - aa_engine_pkg.assets.utils.utilities - INFO - Memory usage of dataframe is 834.67 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  48 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=12)]: Done 138 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=12)]: Done 264 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=12)]: Done 624 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=12)]: Done 858 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=12)]: Done 1000 out of 1000 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-04 18:13:29,621 - aa_engine_pkg.assets.utils.utilities - INFO - Memory usage after optimization is: 418.65 MB\n",
      "2021-01-04 18:13:29,622 - aa_engine_pkg.assets.utils.utilities - INFO - Decreased by 49.8%\n",
      "2021-01-04 18:13:29,623 - aa_engine_pkg.assets.utils.utilities - INFO - Exporting 115524 rows and 946 columns\n"
     ]
    }
   ],
   "source": [
    "for date in dates:\n",
    "    print(f\"Processing date {date}\")\n",
    "    cliente_activo_df= create_cliente_activo(cliente_activo,date)\n",
    "\n",
    "    table='arpu_quality'\n",
    "    master_arpu_quality=pd.read_parquet(path+f'{table}/master_{table}_{date}.parquet')\n",
    "    table='campanas'\n",
    "    master_campanas=pd.read_parquet(path+f'{table}/master_{table}_{date}.parquet')\n",
    "    table='clientes'\n",
    "    master_clientes=pd.read_parquet(path+f'{table}/master_{table}_{date}.parquet')\n",
    "    table='eop'\n",
    "    master_eop=pd.read_parquet(path+f'{table}/master_{table}_{date}.parquet')\n",
    "    table='plan_evento'\n",
    "    master_plan_evento=pd.read_parquet(path+f'{table}/master_{table}_{date}.parquet')\n",
    "    table='servicioalcliente'\n",
    "    master_servicioalcliente=pd.read_parquet(path+f'{table}/master_{table}_{date}.parquet')\n",
    "    table='mudanza'\n",
    "    master_mudanza=pd.read_parquet(path+f'{table}/master_{table}_{date}.parquet')\n",
    "    table='echi'\n",
    "    master_echi=pd.read_parquet(path+f'{table}/master_{table}_{date}.parquet')\n",
    "    table='mantenimiento'\n",
    "    master_mantenimiento=pd.read_parquet(path+f'{table}/master_{table}_{date}.parquet')\n",
    "    table='mora'\n",
    "    master_mora=pd.read_parquet(path+f'{table}/master_{table}_{date}.parquet')\n",
    "    table='eventos_facturados'\n",
    "    master_eventos_fact=pd.read_parquet(path+f'{table}/master_{table}_{date}.parquet')\n",
    "    \n",
    "    create_master_total(cliente_activo_df,\n",
    "                        master_arpu_quality,\n",
    "                        master_campanas,\n",
    "                        master_clientes,\n",
    "                        master_eop,\n",
    "                        master_plan_evento,\n",
    "                        master_servicioalcliente,\n",
    "                        master_mudanza,\n",
    "                        master_echi,\n",
    "                        master_mantenimiento,\n",
    "                        master_mora,\n",
    "                        master_eventos_fact,\n",
    "                        parameters,\n",
    "                        date)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
