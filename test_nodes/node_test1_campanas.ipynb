{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load kedro environment (not needed in .py)\n",
    "from pathlib import Path\n",
    "from kedro.framework.context import load_context\n",
    "\n",
    "# Load a context to be able to work in the notebook\n",
    "#current_dir = Path.cwd()\n",
    "current_dir = Path(\"/u01/share/cesar/aa_engine_uy/notebooks/\")\n",
    "proj_path = current_dir.parent\n",
    "context = load_context(proj_path)\n",
    "catalog = context.catalog\n",
    "credentials = context.config_loader.get(\"credentials*\",\"credentials*/**\")\n",
    "parameters = context.config_loader.get(\"parameters*\",\"parameters*/**\")\n",
    "\n",
    "from aa_engine_pkg.assets.utils import *\n",
    "from aa_engine_pkg.assets.core.data.kedro.catalog_expansion.partitioned_sql import SQLPartitionedDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "date='20180605'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cliente_activo(cliente_activo: SQLPartitionedDataSet,\n",
    "                          date: str) -> pd.DataFrame:\n",
    "    \"\"\"Creates master table with features related to EoP state of customers for one period of data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cliente_activo:\n",
    "        dataset defined in ´catalog.yml´ - list of active customers at EoP for the given period\n",
    "    date:\n",
    "        period to process\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        Mastertable with information of clientes at EoP\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize logger\n",
    "    log = initialize_logger()\n",
    "\n",
    "    # Load active clientes for period\n",
    "    log.info(f\"Creating cliente_activo...\")\n",
    "    period_to_load = get_previous_month(date)\n",
    "    df_clientes_activos = cliente_activo.filter_by(date=period_to_load)\n",
    "\n",
    "    # Return\n",
    "    return df_clientes_activos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-30 12:02:01,910 - kedro.io.data_catalog - INFO - Loading data from `cliente_activo` (SQLPartitionedDataSet)...\n"
     ]
    }
   ],
   "source": [
    "cliente_activo=catalog.load(\"cliente_activo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-30 12:02:04,513 - aa_engine_pkg.assets.utils.utilities - INFO - Creating cliente_activo...\n",
      "select distinct CUSTOMER_ID from stg_uy_customer_status where UPPER(STATUS) LIKE '%ACTIVO%' and DATE_EXP = 201805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u01/miniconda3/envs/uypo37/lib/python3.7/site-packages/sqlalchemy/dialects/oracle/base.py:1381: SAWarning: Oracle version (19, 5, 0, 0, 0) is known to have a maximum identifier length of 128, rather than the historical default of 30. SQLAlchemy 1.4 will use 128 for this database; please set max_identifier_length=128 in create_engine() in order to test the application with this new length, or set to 30 in order to assure that 30 continues to be used.  In particular, pay close attention to the behavior of database migrations as dynamically generated names may change. See the section 'Max Identifier Lengths' in the SQLAlchemy Oracle dialect documentation for background.\n",
      "  % ((self.server_version_info,))\n"
     ]
    }
   ],
   "source": [
    "cliente_activo_df= create_cliente_activo(cliente_activo,date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-30 12:04:42,712 - kedro.io.data_catalog - INFO - Loading data from `campanas` (SQLPartitionedDataSet)...\n"
     ]
    }
   ],
   "source": [
    "campanas= catalog.load(\"campanas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vars_to_dummy = [\"OFERTA_COMBINADA\"]\n",
    "\n",
    "past_periods = [14, 21, 28, 84, 168, 252, 336]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-30 12:04:44,366 - aa_engine_pkg.assets.utils.utilities - INFO - Loading campanas...\n",
      "select * from stg_uy_campana where START_DATE >= to_date('20170704', 'yyyymmdd') and START_DATE < to_date('20180605', 'yyyymmdd')\n"
     ]
    }
   ],
   "source": [
    "# Read parameters\n",
    "log = initialize_logger()\n",
    "look_back_days = parameters[\"masters\"][\"campanas\"][\"look_back_days\"]\n",
    "start_date = (pd.to_datetime(date) - timedelta(days=look_back_days)).strftime(\"%Y%m%d\")\n",
    "\n",
    "# Calculate period to load for active clients\n",
    "period_to_load = get_previous_month(date)\n",
    "log.info(f\"Loading campanas...\")\n",
    "df_campanas = campanas.filter_by(date=[start_date, date]).drop_duplicates()\n",
    "\n",
    "df_clientes = cliente_activo_df\n",
    "\n",
    "df_campanas = pd.merge(df_clientes,\n",
    "                       df_campanas,\n",
    "                       on=[\"CUSTOMER_ID\"],\n",
    "                       how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-30 12:04:48,549 - aa_engine_pkg.assets.utils.utilities - INFO - Creating variables...\n"
     ]
    }
   ],
   "source": [
    "log.info(\"Creating variables...\")\n",
    "# Calculate offer duration / days since start / until end\n",
    "df_campanas['OFFER_DURATION'] = (pd.to_datetime(df_campanas.END_DATE,\n",
    "                                                errors=\"coerce\") - df_campanas.START_DATE) / np.timedelta64(1,\n",
    "                                                                                                            \"D\")\n",
    "df_campanas[\"DAYS_SINCE_START_OFFER\"] = (pd.to_datetime(date) - df_campanas.START_DATE) / np.timedelta64(1, \"D\")\n",
    "df_campanas[\"DAYS_TO_END_OFFER\"] = (pd.to_datetime(df_campanas.END_DATE, errors=\"coerce\") - pd.to_datetime(\n",
    "    date)) / np.timedelta64(1, \"D\")\n",
    "\n",
    "# Extract percentages of offers from their description\n",
    "df_campanas[\"PORC_OFFER\"] = df_campanas[\"DESCRIPTION\"].str.extract(r'(\\d+)%')[0].astype(float)\n",
    "\n",
    "# Extract discount values of offers from their description\n",
    "df_campanas[\"VALUE_OFFER\"] = df_campanas[\"DESCRIPTION\"].str.extract(r'\\$(\\d+)')[0].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>ID</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>SHUSERNR</th>\n",
       "      <th>EXTERNAL_AGENT_ID</th>\n",
       "      <th>USUARIO</th>\n",
       "      <th>DATE_EXP</th>\n",
       "      <th>OFFER_DURATION</th>\n",
       "      <th>DAYS_SINCE_START_OFFER</th>\n",
       "      <th>DAYS_TO_END_OFFER</th>\n",
       "      <th>PORC_OFFER</th>\n",
       "      <th>VALUE_OFFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146099</td>\n",
       "      <td>2018-04-14</td>\n",
       "      <td>2018-04-15</td>\n",
       "      <td>4046</td>\n",
       "      <td>4046 - Upgrade Montevideo $0 Conexion</td>\n",
       "      <td>8026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESALES_UY</td>\n",
       "      <td>201804</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150709</td>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>2534</td>\n",
       "      <td>2534-RETPREM-IN-HOTPACK 1 MES GRATIS+2 MESES(2...</td>\n",
       "      <td>8810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO_MVALLEJO</td>\n",
       "      <td>201802</td>\n",
       "      <td>28.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150709</td>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>2018-05-12</td>\n",
       "      <td>2533</td>\n",
       "      <td>2533 - VENTA HOTPACK 2 Meses al 50%</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IBSINFRA_UY</td>\n",
       "      <td>201803</td>\n",
       "      <td>61.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150709</td>\n",
       "      <td>2018-05-19</td>\n",
       "      <td>2018-07-19</td>\n",
       "      <td>2544</td>\n",
       "      <td>2544-VENTAS PREM-FOX+/FOX HD FREE x 2 meses+ 2...</td>\n",
       "      <td>8810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CO_MVALLEJO</td>\n",
       "      <td>201805</td>\n",
       "      <td>61.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150709</td>\n",
       "      <td>2018-04-19</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>4046</td>\n",
       "      <td>4046 - Upgrade Montevideo $0 Conexion</td>\n",
       "      <td>8026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESALES_UY</td>\n",
       "      <td>201804</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CUSTOMER_ID START_DATE   END_DATE    ID  \\\n",
       "0       146099 2018-04-14 2018-04-15  4046   \n",
       "1       150709 2018-02-12 2018-03-12  2534   \n",
       "2       150709 2018-03-12 2018-05-12  2533   \n",
       "3       150709 2018-05-19 2018-07-19  2544   \n",
       "4       150709 2018-04-19 2018-04-20  4046   \n",
       "\n",
       "                                         DESCRIPTION  SHUSERNR  \\\n",
       "0              4046 - Upgrade Montevideo $0 Conexion      8026   \n",
       "1  2534-RETPREM-IN-HOTPACK 1 MES GRATIS+2 MESES(2...      8810   \n",
       "2                2533 - VENTA HOTPACK 2 Meses al 50%        12   \n",
       "3  2544-VENTAS PREM-FOX+/FOX HD FREE x 2 meses+ 2...      8810   \n",
       "4              4046 - Upgrade Montevideo $0 Conexion      8026   \n",
       "\n",
       "   EXTERNAL_AGENT_ID      USUARIO DATE_EXP  OFFER_DURATION  \\\n",
       "0                NaN    ESALES_UY   201804             1.0   \n",
       "1                NaN  CO_MVALLEJO   201802            28.0   \n",
       "2                NaN  IBSINFRA_UY   201803            61.0   \n",
       "3                NaN  CO_MVALLEJO   201805            61.0   \n",
       "4                NaN    ESALES_UY   201804             1.0   \n",
       "\n",
       "   DAYS_SINCE_START_OFFER  DAYS_TO_END_OFFER  PORC_OFFER  VALUE_OFFER  \n",
       "0                    52.0              -51.0         NaN          0.0  \n",
       "1                   113.0              -85.0         NaN          NaN  \n",
       "2                    85.0              -24.0        50.0          NaN  \n",
       "3                    17.0               44.0        50.0          NaN  \n",
       "4                    47.0              -46.0         NaN          0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_campanas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-30 12:04:51,372 - numexpr.utils - INFO - Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2020-12-30 12:04:51,373 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "# Make a mask with position of values\n",
    "maskvalue = df_campanas[\"VALUE_OFFER\"].notna()\n",
    "maskporc = df_campanas[\"PORC_OFFER\"].notna()\n",
    "\n",
    "# Create a unique ranking scaled for Percentage and value\n",
    "maskall = dict(zip([\"VALUE_OFFER\", \"PORC_OFFER\"],\n",
    "                   (maskvalue, maskporc)))\n",
    "for var, mask in maskall.items():\n",
    "    df_campanas.loc[mask, \"MONTO_OFFER_SCALED\"] = scale_values(df=df_campanas.loc[mask, :],\n",
    "                                                               vars_to_groupby=[\"DATE_EXP\"],\n",
    "                                                               var_to_scale=var,\n",
    "                                                               by_ranking=False)\n",
    "\n",
    "    # Extract length of offer from their description\n",
    "tuple_len = df_campanas[\"DESCRIPTION\"].str.extract(r'(?:(\\d+)[ ]*M|(\\d+)X)', re.IGNORECASE)[[0, 1]].fillna(\n",
    "    0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campanas[\"LENGTH_OFFER\"] = tuple_len.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo la variable tipo_oferta\n",
    "condlist = [df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"DSCTO|RET|DESC\", na=False),\n",
    "            df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"RENTA\", na=False),\n",
    "            df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"UPGRADE\", na=False),\n",
    "            df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"NUEVO\", na=False),\n",
    "            df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"RECON\")\n",
    "            ]\n",
    "choicelist = [\"RETE\",\n",
    "              \"RENT\",\n",
    "              \"UPGR\",\n",
    "              \"NUEV\",\n",
    "              \"RECO\"]\n",
    "df_campanas[\"TIPO_OFERTA\"] = np.select(condlist, choicelist, default=\"OTROS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo variable tipo de producto de la oferta\n",
    "condlist = [df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\n",
    "    \"PREMIUM|FOX|HBO|EXXXOTICO|HOTPACK|ADULT|CLAXON|HUSTLER\", na=False),\n",
    "            df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"PLATA|ORO|BRONCE|SICO\", na=False),\n",
    "            df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"BUNDLE\", na=False),\n",
    "            df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"NET\", na=False),\n",
    "            ]\n",
    "choicelist = [\"PREMIUM\",\n",
    "              \"BASICO\",\n",
    "              \"BUNDLE\",\n",
    "              \"NET\"]\n",
    "df_campanas[\"PRODUCTO_OFERTA\"] = np.select(condlist, choicelist, default=\"OTROS\")\n",
    "\n",
    "df_campanas[\"OFERTA_COMBINADA\"] = df_campanas[\"TIPO_OFERTA\"] + \"_\" + df_campanas[\"PRODUCTO_OFERTA\"]\n",
    "df_campanas[\"FECHA\"] = df_campanas[\"START_DATE\"].dt.strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UPGR_OTROS', 'RETE_PREMIUM', 'OTROS_PREMIUM', 'RETE_BASICO',\n",
       "       'RETE_OTROS', 'OTROS_OTROS', 'RENT_OTROS', 'OTROS_BASICO'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_campanas.OFERTA_COMBINADA.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-30 12:07:36,579 - aa_engine_pkg.assets.utils.utilities - INFO - ---- OFERTA_COMBINADA\n",
      "2020-12-30 12:07:36,833 - aa_engine_pkg.assets.utils.utilities - INFO - Adding relative date between 20170704 and 20180605\n",
      "2020-12-30 12:07:36,878 - aa_engine_pkg.assets.utils.utilities - INFO - Expanding table for period: 14\n",
      "2020-12-30 12:07:36,913 - aa_engine_pkg.assets.utils.utilities - INFO - Expanding table for period: 21\n",
      "2020-12-30 12:07:36,955 - aa_engine_pkg.assets.utils.utilities - INFO - Expanding table for period: 28\n",
      "2020-12-30 12:07:37,004 - aa_engine_pkg.assets.utils.utilities - INFO - Expanding table for period: 84\n",
      "2020-12-30 12:07:37,101 - aa_engine_pkg.assets.utils.utilities - INFO - Expanding table for period: 168\n",
      "2020-12-30 12:07:37,238 - aa_engine_pkg.assets.utils.utilities - INFO - Expanding table for period: 252\n",
      "2020-12-30 12:07:37,371 - aa_engine_pkg.assets.utils.utilities - INFO - Expanding table for period: 336\n",
      "2020-12-30 12:07:37,869 - aa_engine_pkg.assets.utils.utilities - INFO - Adding relative date between 20170704 and 20180605\n",
      "2020-12-30 12:07:37,904 - aa_engine_pkg.assets.utils.utilities - INFO - Expanding table for period: 14\n",
      "2020-12-30 12:07:37,942 - aa_engine_pkg.assets.utils.utilities - INFO - Expanding table for period: 21\n",
      "2020-12-30 12:07:37,986 - aa_engine_pkg.assets.utils.utilities - INFO - Expanding table for period: 28\n",
      "2020-12-30 12:07:38,035 - aa_engine_pkg.assets.utils.utilities - INFO - Expanding table for period: 84\n",
      "2020-12-30 12:07:38,113 - aa_engine_pkg.assets.utils.utilities - INFO - Expanding table for period: 168\n",
      "2020-12-30 12:07:38,213 - aa_engine_pkg.assets.utils.utilities - INFO - Expanding table for period: 252\n",
      "2020-12-30 12:07:38,313 - aa_engine_pkg.assets.utils.utilities - INFO - Expanding table for period: 336\n"
     ]
    }
   ],
   "source": [
    "# creo las variables dummy\n",
    "df_list = []\n",
    "for var in vars_to_dummy:\n",
    "    log.info(f'---- {var}')\n",
    "    df_list.append(group_categorical_variables(df_campanas,\n",
    "                                               vars_to_groupby=[\"CUSTOMER_ID\", \"FECHA\"],\n",
    "                                               var_to_count=var,\n",
    "                                               other_category=None))\n",
    "\n",
    "# Reduce list of list to create a data table\n",
    "df = reduce(lambda left, right: pd.merge(left, right, on=[\"CUSTOMER_ID\", \"FECHA\"], how=\"outer\"), df_list)\n",
    "\n",
    "ofer_cols = [c for c in df.columns if \"OFERTA\" in c]\n",
    "\n",
    "df[\"N_OFERTAS\"] = df[ofer_cols].sum(axis=1)\n",
    "\n",
    "# Join with num vars and expand\n",
    "df_expanded_offers = add_relative_calculate_past(df=df_campanas[[\"CUSTOMER_ID\",\n",
    "                                                                 \"FECHA\",\n",
    "                                                                 \"DAYS_SINCE_START_OFFER\",\n",
    "                                                                 \"DAYS_TO_END_OFFER\",\n",
    "                                                                 \"LENGTH_OFFER\",\n",
    "                                                                 \"MONTO_OFFER_SCALED\"]],\n",
    "                                                 id_cols=[\"CUSTOMER_ID\"],\n",
    "                                                 periods=past_periods,\n",
    "                                                 agg=[np.nanmean, np.nanmin, np.nanmax],\n",
    "                                                 date_col=\"FECHA\",\n",
    "                                                 start_date=start_date,\n",
    "                                                 end_date=date,\n",
    "                                                 period_freq=\"D\")\n",
    "\n",
    "# Join with num vars and expand\n",
    "df_expanded_products = add_relative_calculate_past(df=df,\n",
    "                                                   id_cols=[\"CUSTOMER_ID\"],\n",
    "                                                   periods=past_periods,\n",
    "                                                   agg=[np.nansum],\n",
    "                                                   date_col=\"FECHA\",\n",
    "                                                   start_date=start_date,\n",
    "                                                   end_date=date,\n",
    "                                                   period_freq=\"D\")\n",
    "\n",
    "# Merge\n",
    "df_final = df_expanded_products.merge(df_expanded_offers, on=\"CUSTOMER_ID\", validate=\"1:1\")\n",
    "\n",
    "# Add date variables\n",
    "df_final[\"DATE_EXP\"] = period_to_load\n",
    "df_final[\"DATE_CALC\"] = date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>N_OFERTAS_nansum_14</th>\n",
       "      <th>OFERTA_COMBINADA_RETE_BASICO_nansum_14</th>\n",
       "      <th>OFERTA_COMBINADA_OTROS_PREMIUM_nansum_14</th>\n",
       "      <th>OFERTA_COMBINADA_RETE_OTROS_nansum_14</th>\n",
       "      <th>OFERTA_COMBINADA_RENT_OTROS_nansum_14</th>\n",
       "      <th>OFERTA_COMBINADA_OTROS_OTROS_nansum_14</th>\n",
       "      <th>OFERTA_COMBINADA_OTROS_BASICO_nansum_14</th>\n",
       "      <th>OFERTA_COMBINADA_UPGR_OTROS_nansum_14</th>\n",
       "      <th>OFERTA_COMBINADA_RETE_PREMIUM_nansum_14</th>\n",
       "      <th>...</th>\n",
       "      <th>MONTO_OFFER_SCALED_nanmin_336</th>\n",
       "      <th>MONTO_OFFER_SCALED_nanmax_336</th>\n",
       "      <th>DAYS_TO_END_OFFER_nanmean_336</th>\n",
       "      <th>DAYS_TO_END_OFFER_nanmin_336</th>\n",
       "      <th>DAYS_TO_END_OFFER_nanmax_336</th>\n",
       "      <th>DAYS_SINCE_START_OFFER_nanmean_336</th>\n",
       "      <th>DAYS_SINCE_START_OFFER_nanmin_336</th>\n",
       "      <th>DAYS_SINCE_START_OFFER_nanmax_336</th>\n",
       "      <th>DATE_EXP</th>\n",
       "      <th>DATE_CALC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-58.000000</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>201805</td>\n",
       "      <td>20180605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>241.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>201805</td>\n",
       "      <td>20180605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>56.666667</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>201805</td>\n",
       "      <td>20180605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>201805</td>\n",
       "      <td>20180605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-61.000000</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>201805</td>\n",
       "      <td>20180605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CUSTOMER_ID  N_OFERTAS_nansum_14  OFERTA_COMBINADA_RETE_BASICO_nansum_14  \\\n",
       "0         8176                  NaN                                     NaN   \n",
       "1         8686                  NaN                                     NaN   \n",
       "2         8855                  NaN                                     NaN   \n",
       "3         8864                  NaN                                     NaN   \n",
       "4         8882                  NaN                                     NaN   \n",
       "\n",
       "   OFERTA_COMBINADA_OTROS_PREMIUM_nansum_14  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "   OFERTA_COMBINADA_RETE_OTROS_nansum_14  \\\n",
       "0                                    NaN   \n",
       "1                                    NaN   \n",
       "2                                    NaN   \n",
       "3                                    NaN   \n",
       "4                                    NaN   \n",
       "\n",
       "   OFERTA_COMBINADA_RENT_OTROS_nansum_14  \\\n",
       "0                                    NaN   \n",
       "1                                    NaN   \n",
       "2                                    NaN   \n",
       "3                                    NaN   \n",
       "4                                    NaN   \n",
       "\n",
       "   OFERTA_COMBINADA_OTROS_OTROS_nansum_14  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "\n",
       "   OFERTA_COMBINADA_OTROS_BASICO_nansum_14  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "\n",
       "   OFERTA_COMBINADA_UPGR_OTROS_nansum_14  \\\n",
       "0                                    NaN   \n",
       "1                                    NaN   \n",
       "2                                    NaN   \n",
       "3                                    NaN   \n",
       "4                                    NaN   \n",
       "\n",
       "   OFERTA_COMBINADA_RETE_PREMIUM_nansum_14  ...  \\\n",
       "0                                      NaN  ...   \n",
       "1                                      NaN  ...   \n",
       "2                                      NaN  ...   \n",
       "3                                      NaN  ...   \n",
       "4                                      NaN  ...   \n",
       "\n",
       "   MONTO_OFFER_SCALED_nanmin_336  MONTO_OFFER_SCALED_nanmax_336  \\\n",
       "0                       0.000000                       0.000000   \n",
       "1                       0.064516                       0.064516   \n",
       "2                       0.000000                       0.208333   \n",
       "3                       0.000000                       0.000000   \n",
       "4                       0.000000                       0.000000   \n",
       "\n",
       "   DAYS_TO_END_OFFER_nanmean_336  DAYS_TO_END_OFFER_nanmin_336  \\\n",
       "0                     -58.000000                         -58.0   \n",
       "1                     241.000000                         241.0   \n",
       "2                      56.666667                         -35.0   \n",
       "3                     123.000000                         -59.0   \n",
       "4                     -61.000000                         -61.0   \n",
       "\n",
       "   DAYS_TO_END_OFFER_nanmax_336  DAYS_SINCE_START_OFFER_nanmean_336  \\\n",
       "0                         -58.0                           59.000000   \n",
       "1                         241.0                          151.000000   \n",
       "2                         179.0                           36.666667   \n",
       "3                         305.0                           60.000000   \n",
       "4                         -61.0                           62.000000   \n",
       "\n",
       "   DAYS_SINCE_START_OFFER_nanmin_336  DAYS_SINCE_START_OFFER_nanmax_336  \\\n",
       "0                               59.0                               59.0   \n",
       "1                              151.0                              151.0   \n",
       "2                               26.0                               48.0   \n",
       "3                               60.0                               60.0   \n",
       "4                               62.0                               62.0   \n",
       "\n",
       "   DATE_EXP  DATE_CALC  \n",
       "0    201805   20180605  \n",
       "1    201805   20180605  \n",
       "2    201805   20180605  \n",
       "3    201805   20180605  \n",
       "4    201805   20180605  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_campanas(campanas: SQLPartitionedDataSet,\n",
    "                           cliente_activo: pd.DataFrame,\n",
    "                           parameters: Union[Dict, None],\n",
    "                           date: str\n",
    "                           ) -> pd.DataFrame:\n",
    "    \"\"\"Creates master table with offer features for one period of data\n",
    "    Parameters\n",
    "    ----------\n",
    "    campanas:\n",
    "        dataset defined in ``catalog_raw.yml`` with raw data information related to client's offers\n",
    "    cliente_activo:\n",
    "        dataset defined in ``catalog_raw.yml`` with raw data information related to active clients at EoP\n",
    "    date:\n",
    "        period to process\n",
    "    parameters:\n",
    "        set of project parameters defined in ``parameters.yml``\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Master table with offer features for one period\n",
    "    \"\"\"\n",
    "\n",
    "    # Read parameters\n",
    "    log = initialize_logger()\n",
    "\n",
    "    write_to_parquet = parameters[\"write_to_parquet\"]\n",
    "    table_name = \"campanas\"\n",
    "    overwrite = parameters[\"masters\"][table_name][\"overwrite\"]\n",
    "\n",
    "    # Check if table was already created\n",
    "    files = get_mastertable_paths_by_period(parameters=parameters, period=date)\n",
    "    match = [str(file) for file in files if table_name in file]\n",
    "\n",
    "    if len(match) > 0 and overwrite is False:\n",
    "        # If table is found, read parquet:\n",
    "        log.info(f\"Reading {match[0]} table\")\n",
    "        df_final = pd.read_parquet(match[0], engine=\"pyarrow\")\n",
    "\n",
    "    else:\n",
    "        # Read parameters\n",
    "        log = initialize_logger()\n",
    "        look_back_days = parameters[\"masters\"][\"campanas\"][\"look_back_days\"]\n",
    "        start_date = (pd.to_datetime(date) - timedelta(days=look_back_days)).strftime(\"%Y%m%d\")\n",
    "\n",
    "        # Calculate period to load for active clients\n",
    "        period_to_load = get_previous_month(date)\n",
    "        log.info(f\"Loading campanas...\")\n",
    "        df_campanas = campanas.filter_by(date=[start_date, date]).drop_duplicates()\n",
    "\n",
    "        df_clientes = cliente_activo\n",
    "\n",
    "        df_campanas = pd.merge(df_clientes,\n",
    "                               df_campanas,\n",
    "                               on=[\"CUSTOMER_ID\"],\n",
    "                               how=\"inner\")\n",
    "\n",
    "        log.info(\"Creating variables...\")\n",
    "        # Calculate offer duration / days since start / until end\n",
    "        df_campanas['OFFER_DURATION'] = (pd.to_datetime(df_campanas.END_DATE,\n",
    "                                                        errors=\"coerce\") - df_campanas.START_DATE) / np.timedelta64(1,\n",
    "                                                                                                                    \"D\")\n",
    "        df_campanas[\"DAYS_SINCE_START_OFFER\"] = (pd.to_datetime(date) - df_campanas.START_DATE) / np.timedelta64(1, \"D\")\n",
    "        df_campanas[\"DAYS_TO_END_OFFER\"] = (pd.to_datetime(df_campanas.END_DATE, errors=\"coerce\") - pd.to_datetime(\n",
    "            date)) / np.timedelta64(1, \"D\")\n",
    "\n",
    "        # Extract percentages of offers from their description\n",
    "        df_campanas[\"PORC_OFFER\"] = df_campanas[\"DESCRIPTION\"].str.extract(r'(\\d+)%')[0].astype(float)\n",
    "\n",
    "        # Extract discount values of offers from their description\n",
    "        df_campanas[\"VALUE_OFFER\"] = df_campanas[\"DESCRIPTION\"].str.extract(r'\\$(\\d+)')[0].astype(float)\n",
    "\n",
    "        # Make a mask with position of values\n",
    "        maskvalue = df_campanas[\"VALUE_OFFER\"].notna()\n",
    "        maskporc = df_campanas[\"PORC_OFFER\"].notna()\n",
    "\n",
    "        # Create a unique ranking scaled for Percentage and value\n",
    "        maskall = dict(zip([\"VALUE_OFFER\", \"PORC_OFFER\"],\n",
    "                           (maskvalue, maskporc)))\n",
    "        for var, mask in maskall.items():\n",
    "            df_campanas.loc[mask, \"MONTO_OFFER_SCALED\"] = scale_values(df=df_campanas.loc[mask, :],\n",
    "                                                                       vars_to_groupby=[\"DATE_EXP\"],\n",
    "                                                                       var_to_scale=var,\n",
    "                                                                       by_ranking=False)\n",
    "\n",
    "            # Extract length of offer from their description\n",
    "        tuple_len = df_campanas[\"DESCRIPTION\"].str.extract(r'(?:(\\d+)[ ]*M|(\\d+)X)', re.IGNORECASE)[[0, 1]].fillna(\n",
    "            0).astype(int)\n",
    "        df_campanas[\"LENGTH_OFFER\"] = tuple_len.sum(axis=1)\n",
    "\n",
    "        # creo la variable tipo_oferta\n",
    "        condlist = [df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"DSCTO|RET|DESC\", na=False),\n",
    "                    df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"RENTA\", na=False),\n",
    "                    df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"UPGRADE\", na=False),\n",
    "                    df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"NUEVO\", na=False),\n",
    "                    df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"RECON\")\n",
    "                    ]\n",
    "        choicelist = [\"RETE\",\n",
    "                      \"RENT\",\n",
    "                      \"UPGR\",\n",
    "                      \"NUEV\",\n",
    "                      \"RECO\"]\n",
    "        df_campanas[\"TIPO_OFERTA\"] = np.select(condlist, choicelist, default=\"OTROS\")\n",
    "\n",
    "        # creo variable tipo de producto de la oferta\n",
    "        condlist = [df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\n",
    "            \"PREMIUM|FOX|HBO|EXXXOTICO|HOTPACK|ADULT|CLAXON|HUSTLER\", na=False),\n",
    "                    df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"PLATA|ORO|BRONCE|SICO\", na=False),\n",
    "                    df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"BUNDLE\", na=False),\n",
    "                    df_campanas[\"DESCRIPTION\"].str.upper().str.contains(\"NET\", na=False),\n",
    "                    ]\n",
    "        choicelist = [\"PREMIUM\",\n",
    "                      \"BASICO\",\n",
    "                      \"BUNDLE\",\n",
    "                      \"NET\"]\n",
    "        df_campanas[\"PRODUCTO_OFERTA\"] = np.select(condlist, choicelist, default=\"OTROS\")\n",
    "\n",
    "        df_campanas[\"OFERTA_COMBINADA\"] = df_campanas[\"TIPO_OFERTA\"] + \"_\" + df_campanas[\"PRODUCTO_OFERTA\"]\n",
    "        df_campanas[\"FECHA\"] = df_campanas[\"START_DATE\"].dt.strftime(\"%Y%m%d\")\n",
    "\n",
    "        # creo las variables dummy\n",
    "        df_list = []\n",
    "        for var in vars_to_dummy:\n",
    "            log.info(f'---- {var}')\n",
    "            df_list.append(group_categorical_variables(df_campanas,\n",
    "                                                       vars_to_groupby=[\"CUSTOMER_ID\", \"FECHA\"],\n",
    "                                                       var_to_count=var,\n",
    "                                                       other_category=None))\n",
    "\n",
    "        # Reduce list of list to create a data table\n",
    "        df = reduce(lambda left, right: pd.merge(left, right, on=[\"CUSTOMER_ID\", \"FECHA\"], how=\"outer\"), df_list)\n",
    "\n",
    "        ofer_cols = [c for c in df.columns if \"OFERTA\" in c]\n",
    "\n",
    "        df[\"N_OFERTAS\"] = df[ofer_cols].sum(axis=1)\n",
    "\n",
    "        # Join with num vars and expand\n",
    "        df_expanded_offers = add_relative_calculate_past(df=df_campanas[[\"CUSTOMER_ID\",\n",
    "                                                                         \"FECHA\",\n",
    "                                                                         \"DAYS_SINCE_START_OFFER\",\n",
    "                                                                         \"DAYS_TO_END_OFFER\",\n",
    "                                                                         \"LENGTH_OFFER\",\n",
    "                                                                         \"MONTO_OFFER_SCALED\"]],\n",
    "                                                         id_cols=[\"CUSTOMER_ID\"],\n",
    "                                                         periods=past_periods,\n",
    "                                                         agg=[np.nanmean, np.nanmin, np.nanmax],\n",
    "                                                         date_col=\"FECHA\",\n",
    "                                                         start_date=start_date,\n",
    "                                                         end_date=date,\n",
    "                                                         period_freq=\"D\")\n",
    "\n",
    "        # Join with num vars and expand\n",
    "        df_expanded_products = add_relative_calculate_past(df=df,\n",
    "                                                           id_cols=[\"CUSTOMER_ID\"],\n",
    "                                                           periods=past_periods,\n",
    "                                                           agg=[np.nansum],\n",
    "                                                           date_col=\"FECHA\",\n",
    "                                                           start_date=start_date,\n",
    "                                                           end_date=date,\n",
    "                                                           period_freq=\"D\")\n",
    "\n",
    "        # Merge\n",
    "        df_final = df_expanded_products.merge(df_expanded_offers, on=\"CUSTOMER_ID\", validate=\"1:1\")\n",
    "\n",
    "        # Add date variables\n",
    "        df_final[\"DATE_EXP\"] = period_to_load\n",
    "        df_final[\"DATE_CALC\"] = date\n",
    "\n",
    "        # Rename table\n",
    "        rename_table(df=df_final,\n",
    "                     preffix=parameters[\"masters\"][\"campanas\"][\"table_preffix\"],\n",
    "                     ids_to_exclude=[\"CUSTOMER_ID\", \"DATE_EXP\", \"DATE_CALC\"]\n",
    "                     )\n",
    "\n",
    "        # Return\n",
    "        log.info(f\"Exporting {df_final.shape[0]} rows and {df_final.shape[1]} columns\")\n",
    "\n",
    "        if write_to_parquet:\n",
    "            file = f\"{parameters['paths']['master_path']}master_{table_name}/master_{table_name}_{date}.parquet\"\n",
    "            df_final.to_parquet(file, engine=\"pyarrow\")\n",
    "\n",
    "    return df_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
