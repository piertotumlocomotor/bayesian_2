{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load kedro environment (not needed in .py)\n",
    "from pathlib import Path\n",
    "from kedro.framework.context import load_context\n",
    "\n",
    "# Load a context to be able to work in the notebook\n",
    "#current_dir = Path.cwd()\n",
    "current_dir = Path(\"/u01/share/cesar/aa_engine_uy/notebooks/\")\n",
    "proj_path = current_dir.parent\n",
    "context = load_context(proj_path)\n",
    "catalog = context.catalog\n",
    "credentials = context.config_loader.get(\"credentials*\",\"credentials*/**\")\n",
    "parameters = context.config_loader.get(\"parameters*\",\"parameters*/**\")\n",
    "from aa_engine_pkg.assets.utils import *\n",
    "from aa_engine_pkg.assets.core.data.kedro.catalog_expansion.partitioned_sql import SQLPartitionedDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-25 19:27:22,983 - kedro.io.data_catalog - INFO - Loading data from `upgrades_basicos` (SQLPartitionedDataSet)...\n",
      "2021-03-25 19:27:22,986 - kedro.io.data_catalog - INFO - Loading data from `eop` (SQLPartitionedDataSet)...\n",
      "2021-03-25 19:27:22,987 - kedro.io.data_catalog - INFO - Loading data from `cliente_activo` (SQLPartitionedDataSet)...\n",
      "2021-03-25 19:27:22,988 - kedro.io.data_catalog - INFO - Loading data from `agendas_basicos` (SQLPartitionedDataSet)...\n"
     ]
    }
   ],
   "source": [
    "upgrades_basicos=catalog.load('upgrades_basicos')\n",
    "eop=catalog.load(\"eop\")\n",
    "cliente_activo=catalog.load(\"cliente_activo\")\n",
    "agendas_basicos=catalog.load(\"agendas_basicos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cliente_activo(cliente_activo: SQLPartitionedDataSet,\n",
    "                          date: str) -> pd.DataFrame:\n",
    "    \"\"\"Creates master table with features related to EoP state of customers for one period of data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cliente_activo:\n",
    "        dataset defined in ´catalog.yml´ - list of active customers at EoP for the given period\n",
    "    date:\n",
    "        period to process\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        Mastertable with information of clientes at EoP\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize logger\n",
    "    log = initialize_logger()\n",
    "\n",
    "    # Load active clientes for period\n",
    "    log.info(f\"Creating cliente_activo...\")\n",
    "    period_to_load = get_previous_month(date)\n",
    "    df_clientes_activos = cliente_activo.filter_by(date=period_to_load)\n",
    "\n",
    "    # Return\n",
    "    return df_clientes_activos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-25 19:27:25,480 - aa_engine_pkg.assets.utils.utilities - INFO - Creating cliente_activo...\n",
      "select distinct CUSTOMER_ID from stg_uy_customer_status where UPPER(STATUS) LIKE '%ACTIVO%' and DATE_EXP = 201909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u01/miniconda3/envs/uypo37/lib/python3.7/site-packages/sqlalchemy/dialects/oracle/base.py:1381: SAWarning: Oracle version (19, 5, 0, 0, 0) is known to have a maximum identifier length of 128, rather than the historical default of 30. SQLAlchemy 1.4 will use 128 for this database; please set max_identifier_length=128 in create_engine() in order to test the application with this new length, or set to 30 in order to assure that 30 continues to be used.  In particular, pay close attention to the behavior of database migrations as dynamically generated names may change. See the section 'Max Identifier Lengths' in the SQLAlchemy Oracle dialect documentation for background.\n",
      "  % ((self.server_version_info,))\n"
     ]
    }
   ],
   "source": [
    "date=\"20191007\"\n",
    "cliente_activo_df=create_cliente_activo(cliente_activo,date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logger\n",
    "log = initialize_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_rank = parameters[\"targets\"][\"target_upsell\"][\"upsell_products_rank\"]\n",
    "product_tecnology=parameters[\"targets\"][\"target_upsell\"][\"product_and_tecnology\"]\n",
    "product_tecnology = {value : key for (key, value) in product_tecnology.items()}\n",
    "\n",
    "start_date = date\n",
    "end_date = (pd.to_datetime(date) + timedelta(days=parameters[\"targets\"][\"target_upsell\"][\"calculation_window\"])\n",
    "            ).strftime(\"%Y%m%d\")\n",
    "cancel_date = (pd.to_datetime(date) + timedelta(days=parameters[\"targets\"][\"target_upsell\"][\"activation_window\"])\n",
    "               ).strftime(\"%Y%m%d\")\n",
    "\n",
    "end_date_upgrades = (pd.to_datetime(date) + timedelta(days=2*parameters[\"targets\"][\"target_upsell\"][\"calculation_window\"])).strftime(\"%Y%m%d\")\n",
    "\n",
    "start_date_agendas = (pd.to_datetime(start_date)-timedelta(days=28)).strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select DATE_EXP, CUSTOMER_ID, PRC_CODIGO, PRODUCTO, PRC_TIPO_ID, TEC_ID, MOP, TENURE from stg_uy_eop_customer where DATE_EXP = 201909 and PRC_TIPO_ID = 3 AND PRC_CODIGO  IN (135, 216, 217, 147, 169)\n"
     ]
    }
   ],
   "source": [
    "# Get EoP active clients from previous period to exclude new clients\n",
    "products_allowed_to_move=tuple([key for (key, value) in product_tecnology.items() if value.find('ORO')==-1]) \n",
    "period_to_load = get_previous_month(start_date)\n",
    "df_clientes = eop.filter_by(condition=f\"PRC_TIPO_ID = 3 AND PRC_CODIGO  IN {products_allowed_to_move}\",\n",
    "                             #base of customers that can made an upgrade\n",
    "                             date=period_to_load)\n",
    "\n",
    "# Get the user tecnology\n",
    "df_clientes[\"tecno_eop\"]=df_clientes[\"PRC_CODIGO\"].map(product_tecnology)\n",
    "df_clientes[\"tecno_eop\"]=[y.split(\" \")[2] for x,y in enumerate(df_clientes[\"tecno_eop\"])]\n",
    "df_clientes[\"tecno_eop\"]=np.where(df_clientes.tecno_eop==\"MIX\",\"SD\",df_clientes.tecno_eop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20628, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clientes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select * from stg_uy_plan_evento where PROD_CATEGORY_ID = 3 and EVENTO_ID IN (107,108,133,142) and FECHA > to_date('20191007235900', 'yyyymmddhh24miss') and FECHA <= to_date('20191202235900', 'yyyymmddhh24miss') and EVENTO_ID = 108 AND PRODUCTO_ID IN (135, 216, 217, 147, 169)\n"
     ]
    }
   ],
   "source": [
    "# Get Upgrades for target creation\n",
    "df_upgrades = upgrades_basicos.filter_by(condition=f\"EVENTO_ID = 108 AND PRODUCTO_ID IN {products_allowed_to_move}\",\n",
    "                                         date=[start_date, end_date_upgrades],\n",
    "                                         target=True)\n",
    "#Tecnology of the basic product.\n",
    "df_upgrades[\"tecno_up\"]=[y.split(\" \")[2] for x,y in enumerate(df_upgrades.PRODUCTO_ID.map(product_tecnology))]\n",
    "df_upgrades[\"tecno_up\"]=np.where(df_upgrades.tecno_up==\"MIX\",\"SD\",df_upgrades.tecno_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1680, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upgrades.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select CUSTOMER_ID, PRODUCTO_ID, PRODUCTO, TRUNC(FECHA) FECHA_AGENDA from stg_uy_plan_evento where PROD_CATEGORY_ID = 3 and EVENTO_ID=100108 and FECHA >= to_date('20190909', 'yyyymmdd') and FECHA < to_date('20191104', 'yyyymmdd')\n"
     ]
    }
   ],
   "source": [
    "#Get Agendas\n",
    "df_agenda = agendas_basicos.filter_by(date=[start_date_agendas, end_date])\n",
    "df_agenda.rename(columns={\"FECHA\":\"FECHA_AGENDA\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select * from stg_uy_plan_evento where PROD_CATEGORY_ID = 3 and EVENTO_ID IN (107,108,133,142) and FECHA > to_date('20191007235900', 'yyyymmddhh24miss') and FECHA <= to_date('20200202235900', 'yyyymmddhh24miss')\n"
     ]
    }
   ],
   "source": [
    "#Get Cancelations\n",
    "df_cancelations = upgrades_basicos.filter_by(date=[start_date,cancel_date], target=True)\n",
    "# Keep only first cancellation by CUSTOMER, PRODUCT\n",
    "df_cancelations.sort_values([\"CUSTOMER_ID\", \"PRODUCTO_ID\", \"FECHA\"], ascending=[False, False, True],\n",
    "                                inplace=True)\n",
    "df_cancelations.drop_duplicates(subset=[\"CUSTOMER_ID\", \"PRODUCTO_ID\"], keep=\"last\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clientes_upgrades = pd.merge(\n",
    "            df_clientes[[\"CUSTOMER_ID\", \"PRC_CODIGO\",\"tecno_eop\"]],\n",
    "            df_upgrades[[\"CUSTOMER_ID\", \"PRODUCTO_ID\", \"FECHA\",\"tecno_up\"]],\n",
    "            on=[\"CUSTOMER_ID\"],\n",
    "            how=\"inner\",\n",
    "            validate=\"1:m\")\n",
    "\n",
    "df_clientes_upgrades.sort_values([\"CUSTOMER_ID\", \"PRC_CODIGO\", \"FECHA\"], ascending=[False, False, True],inplace=True)\n",
    "df_clientes_upgrades.drop_duplicates(subset=[\"CUSTOMER_ID\", \"PRC_CODIGO\"], keep=\"last\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clientes_upgrades.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_rank = pd.DataFrame(product_rank.items(), columns=[\"PRODUCTO_RANK_INI\", \"PRC_CODIGO\"]).explode(\"PRC_CODIGO\")\n",
    "\n",
    "# Rank initial product (PRC_CODIGO) from EOP table\n",
    "df_clientes_upgrades_ranked = pd.merge(df_clientes_upgrades,\n",
    "                                   df_product_rank,\n",
    "                                   on=\"PRC_CODIGO\",\n",
    "                                   how=\"left\",\n",
    "                                   validate=\"m:1\")\n",
    "\n",
    "# Rank last product (PRODUCTO_ID) from plan_evento table\n",
    "df_product_rank.rename(columns={\"PRC_CODIGO\": \"PRODUCTO_ID\",\"PRODUCTO_RANK_INI\": \"PRODUCTO_RANK_END\"}, inplace=True)\n",
    "df_clientes_upgrades_ranked = pd.merge(df_clientes_upgrades_ranked,\n",
    "                                       df_product_rank,\n",
    "                                       on=\"PRODUCTO_ID\",\n",
    "                                       how=\"left\",\n",
    "                                       validate=\"m:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-25 19:27:42,076 - aa_engine_pkg.assets.utils.utilities - INFO -  Number of events 108 ending as upgrades 31\n"
     ]
    }
   ],
   "source": [
    "# Calculate target based on initial and end product plus tecnology\n",
    "mask=(df_clientes_upgrades_ranked[\"PRODUCTO_RANK_END\"] > df_clientes_upgrades_ranked[\"PRODUCTO_RANK_INI\"]) & (df_clientes_upgrades_ranked[\"tecno_eop\"] ==df_clientes_upgrades_ranked[\"tecno_up\"])\n",
    "df_clientes_upgrades_ranked[\"TARGET\"] = np.where(mask, 1, 0)\n",
    "log.info(f\" Number of events 108 ending as upgrades {df_clientes_upgrades_ranked.TARGET.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-25 19:27:43,250 - aa_engine_pkg.assets.utils.utilities - INFO -  Number of events 108 ending as upgrades after product changes rule 28\n"
     ]
    }
   ],
   "source": [
    "# Merge with target df to check for activation period\n",
    "df_target = pd.merge(df_clientes_upgrades_ranked,\n",
    "                     df_cancelations[[\"CUSTOMER_ID\", \"PRODUCTO_ID\", \"FECHA\"]],\n",
    "                     on=[\"CUSTOMER_ID\", \"PRODUCTO_ID\"],\n",
    "                     how=\"left\")\n",
    "\n",
    "\n",
    "# Compute time difference between events\n",
    "df_target[\"DATE_DIFF\"] = (df_target[\"FECHA_y\"] - df_target[\"FECHA_x\"]) / np.timedelta64(1, \"D\")\n",
    "df_target[\"TARGET\"] = np.where((df_target[\"DATE_DIFF\"] > 0) & \\\n",
    "                               (df_target[\"DATE_DIFF\"] <= parameters[\"targets\"][\"target_upsell\"][\n",
    "                                   \"activation_window\"]),\n",
    "                               0,\n",
    "                               df_target[\"TARGET\"])\n",
    "log.info(f\" Number of events 108 ending as upgrades after product changes rule {df_target.TARGET.sum()}\")\n",
    "df_target = drop_extra_rename_remaining(df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates prioritizing upgrades\n",
    "df_target.sort_values([\"CUSTOMER_ID\", \"TARGET\"], ascending=False,inplace=True)\n",
    "df_target.drop_duplicates(subset=[\"CUSTOMER_ID\"], keep=\"first\", inplace=True)\n",
    "\n",
    "\n",
    "# quitar upgrades agendados el mes anterior\n",
    "df_final = pd.merge(df_target,\n",
    "                df_agenda,\n",
    "                left_on=['CUSTOMER_ID','PRC_CODIGO'],\n",
    "                right_on=['CUSTOMER_ID','PRODUCTO_ID'],\n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quitar agendas mes anterior\n",
    "upgrades_agendados_antes = df_final[(df_final.FECHA_AGENDA)<(pd.to_datetime(start_date)).strftime(\"%Y%m%d\")]\n",
    "df_final = df_final.drop(upgrades_agendados_antes.index)\n",
    "\n",
    "# quitar upgrades mes futuro no agendados este mes\n",
    "upgrades_futuros = df_final[df_final.FECHA>(pd.to_datetime(start_date)+timedelta(days=28)).strftime(\"%Y%m%d\")]\n",
    "df_final = df_final.drop(upgrades_futuros[upgrades_futuros.FECHA_AGENDA.isna()].index)\n",
    "\n",
    "df_final.sort_values([\"CUSTOMER_ID\", \"TARGET\"], ascending=False,inplace=True)\n",
    "df_final.drop_duplicates(subset=[\"CUSTOMER_ID\"], keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.TARGET.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
