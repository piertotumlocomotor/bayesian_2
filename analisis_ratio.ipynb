{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load kedro environment (not needed in .py)\n",
    "from pathlib import Path\n",
    "from kedro.framework.context import load_context\n",
    "\n",
    "# Load a context to be able to work in the notebook\n",
    "#current_dir = Path.cwd()\n",
    "current_dir = Path(\"/u01/share/cesar/aa_engine_uy/notebooks/\")\n",
    "proj_path = current_dir.parent\n",
    "context = load_context(proj_path)\n",
    "catalog = context.catalog\n",
    "credentials = context.config_loader.get(\"credentials*\",\"credentials*/**\")\n",
    "parameters = context.config_loader.get(\"parameters*\",\"parameters*/**\")\n",
    "\n",
    "from aa_engine_pkg.assets.utils import *\n",
    "from aa_engine_pkg.assets.core.data.kedro.catalog_expansion.partitioned_sql import SQLPartitionedDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-21 15:03:28,776 - kedro.io.data_catalog - INFO - Loading data from `arpu_quality` (SQLPartitionedDataSet)...\n",
      "2021-05-21 15:03:28,778 - kedro.io.data_catalog - INFO - Loading data from `eop` (SQLPartitionedDataSet)...\n",
      "2021-05-21 15:03:28,779 - kedro.io.data_catalog - INFO - Loading data from `campanas` (SQLPartitionedDataSet)...\n",
      "2021-05-21 15:03:28,780 - kedro.io.data_catalog - INFO - Loading data from `cliente_activo` (SQLPartitionedDataSet)...\n"
     ]
    }
   ],
   "source": [
    "arpu=catalog.load('arpu_quality')\n",
    "prod_basico=catalog.load('eop')\n",
    "campanas=catalog.load('campanas')\n",
    "cliente_activo=catalog.load(\"cliente_activo\")\n",
    "date='20210405'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-21 15:03:31,706 - aa_engine_pkg.assets.utils.utilities - INFO - Creating cliente_activo...\n",
      "select distinct CUSTOMER_ID from stg_uy_eop_customer where PRC_TIPO_ID = 3 and DATE_EXP = 202103\n"
     ]
    }
   ],
   "source": [
    "cliente_activo_df= create_cliente_activo(cliente_activo,date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6003 - RET - IN - $350 x 6 meses\t1017\t1%\n",
    "- 493-RET- BONIF BASICO PROP S/CARGO\t831\t1%\n",
    "- 004 - RET - IN - $350 x 12 meses\t820\t1%\n",
    "- 5995 - RET - IN - 670 x 9 meses\t665\t0%\n",
    "- 7321 - RET IN - ADICIONALES - $91 x 12 Meses\t651\t0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6003, 493, 6004, 5995, 7321)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offre_id=tuple([6003,493,6004,5995,7321])\n",
    "offre_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-21 15:06:12,832 - aa_engine_pkg.assets.utils.utilities - INFO - Loading arpu\n",
      "select * from stg_uy_arpu_quality where CHARGES_YYYYMM in ('202104', '202103', '202102')\n",
      "2021-05-21 15:07:08,266 - aa_engine_pkg.assets.utils.utilities - INFO - Read arpu 348414 clientes\n",
      "2021-05-21 15:07:08,269 - aa_engine_pkg.assets.utils.utilities - INFO - Loading eop for {date_exp}\n",
      "select DATE_EXP, CUSTOMER_ID, PRC_CODIGO, PRODUCTO, PRC_TIPO_ID, TEC_ID, MOP, TENURE from stg_uy_eop_customer where DATE_EXP = 202103\n",
      "2021-05-21 15:07:44,068 - aa_engine_pkg.assets.utils.utilities - INFO - Read eop 393146 clientes\n",
      "2021-05-21 15:07:44,070 - aa_engine_pkg.assets.utils.utilities - INFO - Loading campanas...\n",
      "2021-05-21 15:07:45,270 - aa_engine_pkg.assets.utils.utilities - INFO - Read campanas 7227 clientes\n"
     ]
    }
   ],
   "source": [
    "# Initialize logger\n",
    "log = initialize_logger()\n",
    "# Load data for required period\n",
    "look_back_months = 3\n",
    "periods_to_load = get_last_k_periods(date, look_back_months)\n",
    "start_date = periods_to_load[-1]\n",
    "periods_to_load = tuple(periods_to_load)\n",
    "period_to_load = get_previous_month(date)\n",
    "\n",
    "# Get arpu_quality table\n",
    "log.info(\"Loading arpu\")\n",
    "df_arpu = arpu.filter_by_period(date=periods_to_load).drop_duplicates()\n",
    "log.info(f\"Read arpu {df_arpu.shape[0]} clientes\")\n",
    "\n",
    "date_exp = get_previous_month(date)\n",
    "log.info(\"Loading eop for {date_exp}\")\n",
    "df_basico = prod_basico.filter_by_period(date=date_exp).drop_duplicates()\n",
    "log.info(f\"Read eop {df_basico.shape[0]} clientes\")\n",
    "\n",
    "# Calculate period to load for active clients\n",
    "log.info(f\"Loading campanas...\")\n",
    "df_campanas = campanas.filter_by_query(query=f\"select CUSTOMER_ID,ID, DESCRIPTION, START_DATE,END_DATE from stg_uy_campana where START_DATE<=to_date({date}, 'yyyymmdd') AND END_DATE>to_date({date}, 'yyyymmdd') AND ID in {offre_id}\").drop_duplicates()\n",
    "log.info(f\"Read campanas {df_campanas.shape[0]} clientes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arpu_agrupado=df_arpu.groupby([\"CUSTOMER_ID\"]).agg({\"ARPU\":\"mean\"}).rename(columns={\"ARPU\":\"ARPU_MEAN\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prd_arpu=df_basico.loc[(df_basico.PRC_TIPO_ID==3) & (df_basico.CUSTOMER_ID.isin(cliente_activo_df.CUSTOMER_ID))].merge(df_arpu_agrupado[[\"CUSTOMER_ID\",\"ARPU_MEAN\"]],on=\"CUSTOMER_ID\",how=\"left\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56102910    1\n",
       "56053892    1\n",
       "879366      1\n",
       "53330850    1\n",
       "854794      1\n",
       "           ..\n",
       "220990      1\n",
       "52258374    1\n",
       "821061      1\n",
       "56139590    1\n",
       "56098816    1\n",
       "Name: CUSTOMER_ID, Length: 115470, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prd_arpu.CUSTOMER_ID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campanas[\"val\"]=1\n",
    "df_offers=df_campanas.pivot_table(index=\"CUSTOMER_ID\",columns=\"DESCRIPTION\",values=\"val\")\n",
    "df_offers.fillna(0,inplace=True)\n",
    "df_offers[\"n_offers\"]=df_offers.sum(axis=1)\n",
    "df_offers.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df_prd_arpu[[\"DATE_EXP\",\"CUSTOMER_ID\",\"PRODUCTO\",\"ARPU_MEAN\"]].merge(df_offers, on=\"CUSTOMER_ID\",how=\"left\")\n",
    "data.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_EXP</th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>PRODUCTO</th>\n",
       "      <th>ARPU_MEAN</th>\n",
       "      <th>493-RET- BONIF BASICO PROP S/CARGO</th>\n",
       "      <th>5995 - RET - IN - 670 x 9 meses</th>\n",
       "      <th>6003 - RET - IN - $350 x 6 meses</th>\n",
       "      <th>6004 - RET - IN - $350 x 12 meses</th>\n",
       "      <th>7321 - RET IN - ADICIONALES - $91 x 12 Meses</th>\n",
       "      <th>n_offers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202103</td>\n",
       "      <td>1842700</td>\n",
       "      <td>DIRECTV ORO MIX</td>\n",
       "      <td>2662.003333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202103</td>\n",
       "      <td>1843500</td>\n",
       "      <td>DIRECTV PLATA</td>\n",
       "      <td>2048.360000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202103</td>\n",
       "      <td>1845000</td>\n",
       "      <td>DIRECTV PLATA</td>\n",
       "      <td>1394.523333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202103</td>\n",
       "      <td>1846300</td>\n",
       "      <td>DIRECTV ORO MIX</td>\n",
       "      <td>1722.520000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202103</td>\n",
       "      <td>1847600</td>\n",
       "      <td>DIRECTV ORO MIX</td>\n",
       "      <td>1477.440000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DATE_EXP  CUSTOMER_ID         PRODUCTO    ARPU_MEAN  \\\n",
       "0   202103      1842700  DIRECTV ORO MIX  2662.003333   \n",
       "1   202103      1843500    DIRECTV PLATA  2048.360000   \n",
       "2   202103      1845000    DIRECTV PLATA  1394.523333   \n",
       "3   202103      1846300  DIRECTV ORO MIX  1722.520000   \n",
       "4   202103      1847600  DIRECTV ORO MIX  1477.440000   \n",
       "\n",
       "   493-RET- BONIF BASICO PROP S/CARGO  5995 - RET - IN - 670 x 9 meses  \\\n",
       "0                                 0.0                              0.0   \n",
       "1                                 0.0                              0.0   \n",
       "2                                 0.0                              0.0   \n",
       "3                                 0.0                              0.0   \n",
       "4                                 0.0                              0.0   \n",
       "\n",
       "   6003 - RET - IN - $350 x 6 meses  6004 - RET - IN - $350 x 12 meses  \\\n",
       "0                               0.0                                0.0   \n",
       "1                               0.0                                0.0   \n",
       "2                               0.0                                0.0   \n",
       "3                               0.0                                0.0   \n",
       "4                               0.0                                0.0   \n",
       "\n",
       "   7321 - RET IN - ADICIONALES - $91 x 12 Meses  n_offers  \n",
       "0                                           0.0       0.0  \n",
       "1                                           0.0       0.0  \n",
       "2                                           0.0       0.0  \n",
       "3                                           0.0       0.0  \n",
       "4                                           0.0       0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(f\"/u01/share/cesar/arpu_analisi_offer_uy/analisis_{date}.csv\",decimal=\",\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cliente_activo(cliente_activo: SQLPartitionedDataSet,\n",
    "                          date: str) -> pd.DataFrame:\n",
    "    \"\"\"Creates master table with features related to EoP state of customers for one period of data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cliente_activo:\n",
    "        dataset defined in ´catalog.yml´ - list of active customers at EoP for the given period\n",
    "    date:\n",
    "        period to process\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        Mastertable with information of clientes at EoP\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize logger\n",
    "    log = initialize_logger()\n",
    "\n",
    "    # Load active clientes for period\n",
    "    log.info(f\"Creating cliente_activo...\")\n",
    "    period_to_load = get_previous_month(date)\n",
    "    df_clientes_activos = cliente_activo.filter_by(date=period_to_load)\n",
    "\n",
    "    # Return\n",
    "    return df_clientes_activos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliente_activo_df= create_cliente_activo(cliente_activo,date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logger\n",
    "log = initialize_logger()\n",
    "\n",
    "table_name = \"target_xsell\"\n",
    "write_to_parquet = parameters[\"write_to_parquet\"]\n",
    "overwrite = parameters[\"targets\"][table_name][\"overwrite\"]\n",
    "end_date = str(parameters[\"end_date\"])\n",
    "\n",
    "# Check if target can be created (date + max window < end_date)\n",
    "target_parameters = parameters[\"targets\"][table_name]\n",
    "max_window = max([target_parameters[x] for x in target_parameters.keys() if x.endswith(\"window\")])\n",
    "upper_bound = (pd.to_datetime(date) + timedelta(days=max_window)).strftime(\"%Y%m%d\")\n",
    "previous_sunday = dt.today() - timedelta(days=dt.today().weekday()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with what is already processed\n",
    "path = f\"{parameters['paths']['target_path']}{table_name}/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "processed_dates = os.listdir(path)\n",
    "match = [file for file in processed_dates if str(date) in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = date\n",
    "end_date = (pd.to_datetime(date) + timedelta(days=parameters[\"targets\"][table_name][\"calculation_window\"])).strftime(\"%Y%m%d\")\n",
    "cancel_end_date = (pd.to_datetime(date) + timedelta(days=parameters[\"targets\"][table_name][\"activation_window\"])).strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(start_date,end_date,cancel_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for required period\n",
    "df_activaciones = activaciones_premium.filter_by(date=[start_date,\n",
    "                                                       end_date], target=True)\n",
    "log.info(f\"Read {df_activaciones.shape[0]} activations\")\n",
    "df_reconexiones = reconexiones_basicos.filter_by(date=[start_date,\n",
    "                                                       end_date], target=True)\n",
    "log.info(f\"Read {df_reconexiones.shape[0]} reconnections\")\n",
    "df_cancelaciones = cancelaciones_premium.filter_by(date=[start_date,\n",
    "                                                         cancel_end_date], target=True)\n",
    "log.info(f\"Read {df_cancelaciones.shape[0]} cancelations\")\n",
    "\n",
    "# get EoP active clients from previous period to exclude new clients\n",
    "prev_period = get_previous_month(start_date)\n",
    "df_clientes = cliente_activo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(f\"Read {df_clientes.shape[0]} clients\")\n",
    "\n",
    "df_activaciones[vars_to_string] = df_activaciones[vars_to_string].astype(str)\n",
    "df_reconexiones[vars_to_string] = df_reconexiones[vars_to_string].astype(str)\n",
    "df_cancelaciones[vars_to_string] = df_cancelaciones[vars_to_string].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activaciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancelaciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reconexiones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activaciones[\"FECHA\"] = df_activaciones[\"FECHA\"].dt.normalize()\n",
    "df_reconexiones[\"FECHA\"] = df_reconexiones[\"FECHA\"].dt.normalize()\n",
    "\n",
    "if pd.to_datetime(cancel_end_date) > pd.to_datetime(end_date):\n",
    "    df_cancelaciones[\"FECHA\"] = df_cancelaciones[\"FECHA\"].dt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activaciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate premium product activations in current period\n",
    "# merge and keep outer join\n",
    "cp_xsells_multi = pd.merge(df_activaciones,\n",
    "                           df_reconexiones,\n",
    "                           on=vars_to_merge,\n",
    "                           how=\"left\"\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_xsells_multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only customer that are not in both\n",
    "cp_xsells_multi[\"FLAG_ACTIVATION_PREMIUM\"] = np.where(cp_xsells_multi[\"DATE_EXP_y\"].isna(), 1, 0)\n",
    "cp_xsells_multi = cp_xsells_multi[cp_xsells_multi[\"FLAG_ACTIVATION_PREMIUM\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_xsells_multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_xsells_multi = drop_extra_rename_remaining(cp_xsells_multi,\n",
    "                                                      suffix_extra=\"_y\",\n",
    "                                                      suffix_remaining=\"_x\",\n",
    "                                                      suffix_new_name=\"\"\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_xsells_multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(cancel_end_date) > pd.to_datetime(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only last event of xsell in period of interest\n",
    "df_cp_xsells = cp_xsells_multi.sort_values([\"CUSTOMER_ID\", \"PRODUCTO_ID\", \"FECHA\"]\n",
    "                                           ).drop_duplicates(subset=[\"CUSTOMER_ID\", \"PRODUCTO_ID\"],\n",
    "                                                             keep=\"last\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only last event of xsell in period of interest\n",
    "df_cp_xsells = cp_xsells_multi.sort_values([\"CUSTOMER_ID\", \"PRODUCTO_ID\", \"FECHA\"]\n",
    "                                           ).drop_duplicates(subset=[\"CUSTOMER_ID\", \"PRODUCTO_ID\"],\n",
    "                                                             keep=\"last\")\n",
    "if pd.to_datetime(cancel_end_date) > pd.to_datetime(end_date):\n",
    "    df_cp_xsells_cancels = pd.merge(df_cp_xsells,\n",
    "                                    df_cancelaciones,\n",
    "                                    on=[\"CUSTOMER_ID\", \"PRODUCTO_ID\"],\n",
    "                                    how=\"left\",\n",
    "                                    validate=\"1:m\"\n",
    "                                    )\n",
    "\n",
    "    # check time difference between xsell and product cancelation\n",
    "    df_cp_xsells_cancels[\"FECHA_DIFF\"] = (df_cp_xsells_cancels[\"FECHA_y\"] - df_cp_xsells_cancels[\n",
    "        \"FECHA_x\"]) / np.timedelta64(1, \"D\")\n",
    "    df_cp_xsells_cancels = drop_extra_rename_remaining(df_cp_xsells_cancels,\n",
    "                                                       suffix_extra=\"_y\",\n",
    "                                                       suffix_remaining=\"_x\",\n",
    "                                                       suffix_new_name=\"\"\n",
    "                                                       )\n",
    "    mask_cancels_before_buying = (df_cp_xsells_cancels[\"FECHA_DIFF\"] < 0)\n",
    "    mask_cancels_before_activation_window = (df_cp_xsells_cancels[\"FECHA_DIFF\"] >= 0) & \\\n",
    "                                            (df_cp_xsells_cancels[\"FECHA_DIFF\"] <=\n",
    "                                             parameters[\"targets\"][\"target_xsell\"][\"activation_window\"])\n",
    "    df_cp_xsells_cancels[\"TARGET\"] = np.where(\n",
    "        mask_cancels_before_buying | mask_cancels_before_activation_window, 0, 1)\n",
    "else:\n",
    "    df_cp_xsells_cancels = df_cp_xsells.copy()\n",
    "    df_cp_xsells_cancels[\"TARGET\"] = np.where(df_cp_xsells_cancels[\"FLAG_ACTIVATION_PREMIUM\"] == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cp_xsells_cancels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group target products into super category (fox, hbo, adultos) to create target variable\n",
    "cp_xsells_final = df_cp_xsells_cancels.loc[df_cp_xsells_cancels[\"TARGET\"] == 1, \\\n",
    "                                           [\"CUSTOMER_ID\", \"PRODUCTO_ID\", \"PRODUCTO\", \"TARGET\", \"FECHA\"]]\n",
    "condlist = [cp_xsells_final[\"PRODUCTO_ID\"].isin(parameters[\"targets\"][table_name][\"xsell_products\"][\"fox\"]),\n",
    "            cp_xsells_final[\"PRODUCTO_ID\"].isin(parameters[\"targets\"][table_name][\"xsell_products\"][\"hbo\"]),\n",
    "            cp_xsells_final[\"PRODUCTO_ID\"].isin(parameters[\"targets\"][table_name][\"xsell_products\"][\"adultos\"])]\n",
    "\n",
    "# Impute product\n",
    "choicelist = [\"FOX\", \"HBO\", \"ADULTOS\"]\n",
    "cp_xsells_final[\"TARGET_PRODUCT\"] = np.select(condlist, choicelist, default=\"error\")\n",
    "\n",
    "agg_dict = {\"TARGET\": \"max\",\n",
    "            \"FECHA\": \"max\",\n",
    "            \"PRODUCTO_ID\": \"max\"}\n",
    "cp_xsells_final = cp_xsells_final.groupby([\"CUSTOMER_ID\", \"TARGET_PRODUCT\"]).agg(agg_dict).reset_index()\n",
    "\n",
    "target = pd.merge(df_clientes,\n",
    "                  cp_xsells_final,\n",
    "                  on=\"CUSTOMER_ID\",\n",
    "                  how=\"outer\",\n",
    "                  validate=\"1:m\",\n",
    "                  indicator=True)\n",
    "\n",
    "target[\"DATE_EXP\"] = prev_period\n",
    "target[\"TARGET\"].fillna(0, inplace=True)\n",
    "target[\"TARGET_PRODUCT\"].fillna(\"NO_COMPRA\", inplace=True)\n",
    "target[\"PRODUCTO_ID\"].fillna(\"NO_COMPRA\", inplace=True)\n",
    "target[\"TARGET\"] = target[\"TARGET\"].astype(np.int32)\n",
    "target.rename({\"FECHA\": \"FECHA_TARGET\"}, inplace=True)\n",
    "target[\"DATE_CALC\"] = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_xsell(activaciones_premium: SQLPartitionedDataSet,\n",
    "                        reconexiones_basicos: SQLPartitionedDataSet,\n",
    "                        cancelaciones_premium: SQLPartitionedDataSet,\n",
    "                        cliente_activo: pd.DataFrame,\n",
    "                        parameters: Dict,\n",
    "                        date: str) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"The following function will define the target variable for the xsell model of Premium products, considering:\n",
    "    #### Products including:\n",
    "        - FOX\n",
    "        - HBO\n",
    "        - Pack Adultos\n",
    "    #### Target definition:\n",
    "        - Existing customer acquires Premium product\n",
    "        - Stays active for 3 or more months (end of discount price period)\n",
    "    ---\n",
    "    ## Target methodology\n",
    "        1. Identify events 5229 (activation) and 171 (reconnection of product) related to product category 1 (Premium)\n",
    "    and exclude products that are out of scope\n",
    "        2. Identify events 171 (reconnection of product) related to category 3 (basic) products\n",
    "        3. Exclude events from (1.) that happen on the same day as events on (2.) -> Reconnections of basic means churn\n",
    "    involuntario\n",
    "        4. Filter (get latest event) customers that have multiple events on the same product during the same period\n",
    "        5. Check if product was canceled during the following 90 days\n",
    "        6. Create target: \"customer buys any premium product\"\n",
    "        7. Create target_product: \"customer buys this product\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    activaciones_premium:\n",
    "        dataset defined in ``catalog_raw.yml`` with raw data information related to new activations of the set of\n",
    "        Premium products defined above\n",
    "    reconexiones_basicos:\n",
    "        dataset defined in ``catalog_raw.yml`` with raw data information related to reconnections of programming\n",
    "        services after a disconnection due to payment defaults\n",
    "    cancelaciones_premium:\n",
    "        dataset defined in ``catalog_raw.yml`` with raw data information related to product cancelations of the set of\n",
    "        Premium products defined above\n",
    "    cliente_activo:\n",
    "        pandas dataframe with active customers for period\n",
    "    date:\n",
    "        period to process\n",
    "    parameters:\n",
    "        set of project parameters defined in ``parameters.yml``\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        pandas dataframe with xsell target for period\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize logger\n",
    "    log = initialize_logger()\n",
    "\n",
    "    table_name = \"target_xsell\"\n",
    "    write_to_parquet = parameters[\"write_to_parquet\"]\n",
    "    overwrite = parameters[\"targets\"][table_name][\"overwrite\"]\n",
    "    end_date = str(parameters[\"end_date\"])\n",
    "\n",
    "    # Check if target can be created (date + max window < end_date)\n",
    "    target_parameters = parameters[\"targets\"][table_name]\n",
    "    max_window = max([target_parameters[x] for x in target_parameters.keys() if x.endswith(\"window\")])\n",
    "    upper_bound = (pd.to_datetime(date) + timedelta(days=max_window)).strftime(\"%Y%m%d\")\n",
    "    previous_sunday = dt.today() - timedelta(days=dt.today().weekday()+1)\n",
    "    \n",
    "    if pd.to_datetime(upper_bound, format=\"%Y%m%d\") > previous_sunday:\n",
    "        log.info(f\"Cannot create xsell target for {date}: Not enough future information\")\n",
    "        return None\n",
    "\n",
    "    # Compare with what is already processed\n",
    "    path = f\"{parameters['paths']['target_path']}{table_name}/\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    processed_dates = os.listdir(path)\n",
    "    match = [file for file in processed_dates if str(date) in file]\n",
    "\n",
    "    if len(match) > 0 and overwrite is False:\n",
    "        # If table is found, read parquet:\n",
    "        log.info(f\"Reading {match[0]} table\")\n",
    "        target = pd.read_parquet(path + match[0], engine=\"pyarrow\")\n",
    "\n",
    "    else:\n",
    "        start_date = date\n",
    "        end_date = (pd.to_datetime(date) + timedelta(\n",
    "            days=parameters[\"targets\"][table_name][\"calculation_window\"])).strftime(\"%Y%m%d\")\n",
    "        cancel_end_date = (pd.to_datetime(date) + timedelta(\n",
    "            days=parameters[\"targets\"][table_name][\"activation_window\"])).strftime(\"%Y%m%d\")\n",
    "\n",
    "        # Load data for required period\n",
    "        df_activaciones = activaciones_premium.filter_by(date=[start_date,\n",
    "                                                               end_date], target=True)\n",
    "        log.info(f\"Read {df_activaciones.shape[0]} activations\")\n",
    "        df_reconexiones = reconexiones_basicos.filter_by(date=[start_date,\n",
    "                                                               end_date], target=True)\n",
    "        log.info(f\"Read {df_reconexiones.shape[0]} reconnections\")\n",
    "        df_cancelaciones = cancelaciones_premium.filter_by(date=[start_date,\n",
    "                                                                 cancel_end_date], target=True)\n",
    "        log.info(f\"Read {df_cancelaciones.shape[0]} cancelations\")\n",
    "\n",
    "        # get EoP active clients from previous period to exclude new clients\n",
    "        prev_period = get_previous_month(start_date)\n",
    "        df_clientes = cliente_activo\n",
    "\n",
    "        log.info(f\"Read {df_clientes.shape[0]} clients\")\n",
    "\n",
    "        df_activaciones[vars_to_string] = df_activaciones[vars_to_string].astype(str)\n",
    "        df_reconexiones[vars_to_string] = df_reconexiones[vars_to_string].astype(str)\n",
    "        df_cancelaciones[vars_to_string] = df_cancelaciones[vars_to_string].astype(str)\n",
    "\n",
    "        df_activaciones[\"FECHA\"] = df_activaciones[\"FECHA\"].dt.normalize()\n",
    "        df_reconexiones[\"FECHA\"] = df_reconexiones[\"FECHA\"].dt.normalize()\n",
    "\n",
    "        if pd.to_datetime(cancel_end_date) > pd.to_datetime(end_date):\n",
    "            df_cancelaciones[\"FECHA\"] = df_cancelaciones[\"FECHA\"].dt.normalize()\n",
    "\n",
    "        # 1. Calculate premium product activations in current period\n",
    "        # merge and keep outer join\n",
    "        cp_xsells_multi = pd.merge(df_activaciones,\n",
    "                                   df_reconexiones,\n",
    "                                   on=vars_to_merge,\n",
    "                                   how=\"left\"\n",
    "                                   )\n",
    "\n",
    "        # keep only customer that are not in both\n",
    "        cp_xsells_multi[\"FLAG_ACTIVATION_PREMIUM\"] = np.where(cp_xsells_multi[\"DATE_EXP_y\"].isna(), 1, 0)\n",
    "        cp_xsells_multi = cp_xsells_multi[cp_xsells_multi[\"FLAG_ACTIVATION_PREMIUM\"] == 1]\n",
    "        cp_xsells_multi = drop_extra_rename_remaining(cp_xsells_multi,\n",
    "                                                      suffix_extra=\"_y\",\n",
    "                                                      suffix_remaining=\"_x\",\n",
    "                                                      suffix_new_name=\"\"\n",
    "                                                      )\n",
    "\n",
    "        # keep only last event of xsell in period of interest\n",
    "        df_cp_xsells = cp_xsells_multi.sort_values([\"CUSTOMER_ID\", \"PRODUCTO_ID\", \"FECHA\"]\n",
    "                                                   ).drop_duplicates(subset=[\"CUSTOMER_ID\", \"PRODUCTO_ID\"],\n",
    "                                                                     keep=\"last\")\n",
    "        if pd.to_datetime(cancel_end_date) > pd.to_datetime(end_date):\n",
    "            df_cp_xsells_cancels = pd.merge(df_cp_xsells,\n",
    "                                            df_cancelaciones,\n",
    "                                            on=[\"CUSTOMER_ID\", \"PRODUCTO_ID\"],\n",
    "                                            how=\"left\",\n",
    "                                            validate=\"1:m\"\n",
    "                                            )\n",
    "\n",
    "            # check time difference between xsell and product cancelation\n",
    "            df_cp_xsells_cancels[\"FECHA_DIFF\"] = (df_cp_xsells_cancels[\"FECHA_y\"] - df_cp_xsells_cancels[\n",
    "                \"FECHA_x\"]) / np.timedelta64(1, \"D\")\n",
    "            df_cp_xsells_cancels = drop_extra_rename_remaining(df_cp_xsells_cancels,\n",
    "                                                               suffix_extra=\"_y\",\n",
    "                                                               suffix_remaining=\"_x\",\n",
    "                                                               suffix_new_name=\"\"\n",
    "                                                               )\n",
    "            mask_cancels_before_buying = (df_cp_xsells_cancels[\"FECHA_DIFF\"] < 0)\n",
    "            mask_cancels_before_activation_window = (df_cp_xsells_cancels[\"FECHA_DIFF\"] >= 0) & \\\n",
    "                                                    (df_cp_xsells_cancels[\"FECHA_DIFF\"] <=\n",
    "                                                     parameters[\"targets\"][\"target_xsell\"][\"activation_window\"])\n",
    "            df_cp_xsells_cancels[\"TARGET\"] = np.where(\n",
    "                mask_cancels_before_buying | mask_cancels_before_activation_window, 0, 1)\n",
    "        else:\n",
    "            df_cp_xsells_cancels = df_cp_xsells.copy()\n",
    "            df_cp_xsells_cancels[\"TARGET\"] = np.where(df_cp_xsells_cancels[\"FLAG_ACTIVATION_PREMIUM\"] == 1, 1, 0)\n",
    "\n",
    "        # group target products into super category (fox, hbo, adultos) to create target variable\n",
    "        cp_xsells_final = df_cp_xsells_cancels.loc[df_cp_xsells_cancels[\"TARGET\"] == 1, \\\n",
    "                                                   [\"CUSTOMER_ID\", \"PRODUCTO_ID\", \"PRODUCTO\", \"TARGET\", \"FECHA\"]]\n",
    "        condlist = [cp_xsells_final[\"PRODUCTO_ID\"].isin(parameters[\"targets\"][table_name][\"xsell_products\"][\"fox\"]),\n",
    "                    cp_xsells_final[\"PRODUCTO_ID\"].isin(parameters[\"targets\"][table_name][\"xsell_products\"][\"hbo\"]),\n",
    "                    cp_xsells_final[\"PRODUCTO_ID\"].isin(parameters[\"targets\"][table_name][\"xsell_products\"][\"adultos\"])]\n",
    "\n",
    "        # Impute product\n",
    "        choicelist = [\"FOX\", \"HBO\", \"ADULTOS\"]\n",
    "        cp_xsells_final[\"TARGET_PRODUCT\"] = np.select(condlist, choicelist, default=\"error\")\n",
    "\n",
    "        agg_dict = {\"TARGET\": \"max\",\n",
    "                    \"FECHA\": \"max\",\n",
    "                    \"PRODUCTO_ID\": \"max\"}\n",
    "        cp_xsells_final = cp_xsells_final.groupby([\"CUSTOMER_ID\", \"TARGET_PRODUCT\"]).agg(agg_dict).reset_index()\n",
    "\n",
    "        target = pd.merge(df_clientes,\n",
    "                          cp_xsells_final,\n",
    "                          on=\"CUSTOMER_ID\",\n",
    "                          how=\"outer\",\n",
    "                          validate=\"1:m\",\n",
    "                          indicator=True)\n",
    "\n",
    "        target[\"DATE_EXP\"] = prev_period\n",
    "        target[\"TARGET\"].fillna(0, inplace=True)\n",
    "        target[\"TARGET_PRODUCT\"].fillna(\"NO_COMPRA\", inplace=True)\n",
    "        target[\"PRODUCTO_ID\"].fillna(\"NO_COMPRA\", inplace=True)\n",
    "        target[\"TARGET\"] = target[\"TARGET\"].astype(np.int32)\n",
    "        target.rename({\"FECHA\": \"FECHA_TARGET\"}, inplace=True)\n",
    "        target[\"DATE_CALC\"] = date\n",
    "\n",
    "        if write_to_parquet:\n",
    "            file = f\"{parameters['paths']['target_path']}{table_name}/{table_name}_{date}.parquet\"\n",
    "            target.to_parquet(file, engine=\"pyarrow\")\n",
    "\n",
    "        # Return\n",
    "        log.info(\n",
    "            f\"\"\"Exporting target for period {start_date} and rate {\n",
    "            np.round(100 * target[target['TARGET'] == 1]['CUSTOMER_ID'].nunique() / target['CUSTOMER_ID'].nunique(), 2)\n",
    "            }%\"\"\")\n",
    "\n",
    "    return target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
